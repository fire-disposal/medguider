import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import recall_score, f1_score, precision_recall_curve, confusion_matrix
from pyv import CONFIG, EngineeringEngine, generate_engineering_data, PatientProfile

# é¡µé¢é…ç½®
st.set_page_config(page_title="è€å¹´é™ªè¯Šæ¨èç³»ç»Ÿ v0.3", layout="wide")

# åˆå§‹åŒ– Session State
if "config" not in st.session_state:
    st.session_state.config = CONFIG.copy()

# ä¾§è¾¹æ ï¼šé…ç½®å‚æ•°
st.sidebar.header("âš™ï¸ ç³»ç»Ÿå‚æ•°é…ç½®")

with st.sidebar.expander("æƒé‡åˆ†åˆ†é… (Weights)", expanded=True):
    st.session_state.config["weights"]["ability_mu"] = st.slider(
        "èŒä¸šèƒ½åŠ›æƒé‡ (Ability)", 0.0, 1.0, st.session_state.config["weights"]["ability_mu"]
    )
    st.session_state.config["weights"]["attitude_rho"] = st.slider(
        "æœåŠ¡æ€åº¦æƒé‡ (Attitude)", 0.0, 1.0, st.session_state.config["weights"]["attitude_rho"]
    )
    st.session_state.config["weights"]["similarity_lambda"] = st.slider(
        "ç”»åƒå¥‘åˆæƒé‡ (Similarity)", 0.0, 1.0, st.session_state.config["weights"]["similarity_lambda"]
    )
    st.session_state.config["weights"]["active_iota"] = st.slider(
        "æ´»è·ƒ/ç»éªŒæƒé‡ (Active)", 0.0, 1.0, st.session_state.config["weights"]["active_iota"]
    )

st.sidebar.markdown("---")
st.sidebar.header("ğŸ§ª å®éªŒè®¾ç½®")
n_samples = st.sidebar.number_input("æ¨¡æ‹Ÿæ ·æœ¬é‡", 100, 2000, 600)
threshold = st.sidebar.slider("æ¨èåˆ¤å®šé˜ˆå€¼", 0.0, 1.0, st.session_state.config["params"]["satisfaction_threshold"])
st.session_state.config["params"]["satisfaction_threshold"] = threshold

# ä¸»ç•Œé¢
st.title("ğŸ¥ è€å¹´é™ªè¯Šæ¨èç³»ç»Ÿ - äº¤äº’åŒ–å®éªŒå¹³å°")
st.markdown("""
æœ¬ç³»ç»Ÿé€šè¿‡**å¤šç»´åº¦ç”»åƒå»ºæ¨¡**ï¼ˆèƒ½åŠ›ã€æ€åº¦ã€éœ€æ±‚å¥‘åˆåº¦ã€æ´»è·ƒåº¦ï¼‰ä¸ºè€å¹´æ‚£è€…æ¨èæœ€åˆé€‚çš„é™ªè¯Šå‘˜ã€‚
æ‚¨å¯ä»¥é€šè¿‡å·¦ä¾§è¾¹æ è°ƒæ•´ç®—æ³•æƒé‡ï¼Œå®æ—¶è§‚å¯Ÿç³»ç»Ÿåœ¨ä¸“å®¶æ ‡å‡†ä¸‹çš„æ€§èƒ½è¡¨ç°ã€‚
""")

tab1, tab2, tab3 = st.tabs(["ğŸš€ åŒ¹é…å®éªŒä¸è¯„ä¼°", "ğŸ§ ä¸ªæ¡ˆæ·±åº¦åˆ†æ", "ğŸ“Š ç»Ÿè®¡çœ‹æ¿"])

# æ•°æ®å‡†å¤‡
@st.cache_data
def get_data(n):
    return generate_engineering_data(n)

patients, escorts = get_data(n_samples)
engine = EngineeringEngine(st.session_state.config)

# æ‰§è¡Œè¯„ä¼°
train_df, test_df, acc, prec = engine.evaluate_system(patients, escorts)
rec = recall_score(test_df["truth"], test_df["pred"], zero_division=0)
f1 = f1_score(test_df["truth"], test_df["pred"], zero_division=0)

with tab1:
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("å‡†ç¡®ç‡ (Acc)", f"{acc:.4f}")
    col2.metric("ç²¾ç¡®ç‡ (Pre)", f"{prec:.4f}")
    col3.metric("å¬å›ç‡ (Rec)", f"{rec:.4f}")
    col4.metric("F1 åˆ†æ•°", f"{f1:.4f}")

    st.subheader("ğŸ” Top 10 æœ€ä½³åŒ¹é…æ¡ˆä¾‹")
    patient_map = {p.pid: p for p in patients}
    escort_map = {e.eid: e for e in escorts}
    
    top_matches = test_df.sort_values(by="score", ascending=False).head(10)
    
    match_display = []
    for _, row in top_matches.iterrows():
        p = patient_map[row["patient_id"]]
        e = escort_map[row["escort_id"]]
        match_display.append({
            "åŒ¹é…åˆ†": row["score"],
            "æ‚£è€…ID": p.pid,
            "æ‚£è€…éœ€æ±‚": ", ".join(p.survey_tags),
            "é™ªè¯Šå‘˜": e.name,
            "èƒ½åŠ›åˆ†": row["ability"],
            "å¥‘åˆåˆ†": row["similarity"],
            "ä¸“å®¶ç»“è®º": "é¦–é€‰" if row["truth"] == 1 else "å¤‡é€‰"
        })
    st.table(pd.DataFrame(match_display))

with tab2:
    st.subheader("ğŸ” æ¨¡æ‹Ÿå•ä¸ªæ‚£è€…åŒ¹é…")
    p_id = st.selectbox("é€‰æ‹©æµ‹è¯•æ‚£è€… ID", [p.pid for p in patients[:50]])
    target_p = patient_map[p_id]
    
    st.write(f"**æ‚£è€…ç”»åƒ:** {target_p.gender} | {target_p.age}å² | {target_p.education}")
    st.write(f"**æ ¸å¿ƒéœ€æ±‚:** {', '.join(target_p.survey_tags)}")
    
    st.session_state.target_p = target_p # ä¸ºäº†è§¦å‘åˆ·æ–°
    
    # è®¡ç®—å½“å‰æ‚£è€…ä¸æ‰€æœ‰é™ªè¯Šå‘˜çš„åŒ¹é…
    scores = []
    for e in escorts:
        detail = engine.calculate_match_score(target_p, e)
        scores.append({
            "eid": e.eid,
            "name": e.name,
            "score": detail.total_score,
            "ability": detail.ability_component,
            "similarity": detail.similarity_component,
            "attitude": detail.attitude_component,
            "active": detail.active_component
        })
    
    scores_df = pd.DataFrame(scores).sort_values(by="score", ascending=False).head(5)
    
    st.write("---")
    st.write("#### ä¸ºè¯¥æ‚£è€…æ¨èçš„ Top 5 é™ªè¯Šå‘˜ï¼š")
    for _, s in scores_df.iterrows():
        e_obj = escort_map[s["eid"]]
        col_m1, col_m2 = st.columns([1, 2])
        with col_m1:
            st.info(f"**{s['name']}** (å¾—åˆ†: {s['score']:.4f})")
        with col_m2:
            st.write(f"è¯ä¹¦: {', '.join(e_obj.certs) if e_obj.certs else 'æ— '} | è¯„åˆ†: {e_obj.avg_rating}")
            st.progress(s["score"], text=f"ç»¼åˆå¥‘åˆåº¦: {s['score']:.2f}")

with tab3:
    st.subheader("ğŸ“ˆ æ ¸å¿ƒæ€§èƒ½å¯è§†åŒ–")
    
    fig, axes = plt.subplots(2, 2, figsize=(16, 10))
    plt.rcParams["font.sans-serif"] = ["Microsoft YaHei", "SimSun", "Arial Unicode MS"]
    plt.rcParams["axes.unicode_minus"] = False
    
    # 1. P-R Curve
    precisions_curve, recalls_curve, _ = precision_recall_curve(test_df["truth"], test_df["score"])
    axes[0, 0].plot(recalls_curve, precisions_curve, label="P-R Curve", color="darkgreen")
    axes[0, 0].set_xlabel("Recall")
    axes[0, 0].set_ylabel("Precision")
    axes[0, 0].set_title("P-R Curve")
    axes[0, 0].legend()

    # 2. Correlation
    comp_cols = ["ability", "attitude", "similarity", "active", "score"]
    sns.heatmap(test_df[comp_cols].corr(), annot=True, cmap="vlag", ax=axes[0, 1])
    axes[0, 1].set_title("Feature Correlation")

    # 3. Age Groups
    test_df['age_group'] = pd.cut(test_df['p_age'], bins=[60, 70, 80, 95], labels=['60-70', '70-80', '80+'])
    pivot = test_df.pivot_table(values='score', index='age_group', columns='e_cert_count', aggfunc='mean')
    sns.heatmap(pivot, annot=True, fmt=".2f", cmap="YlGnBu", ax=axes[1, 0])
    axes[1, 0].set_title("Score by Age & Certs")

    # 4. Confusion Matrix
    cm = confusion_matrix(test_df["truth"], test_df["pred"])
    cm_norm = cm.astype("float") / cm.sum(axis=1)[:, np.newaxis]
    sns.heatmap(cm_norm, annot=True, fmt=".2%", cmap="Blues", ax=axes[1, 1],
                xticklabels=["Not Rec", "Rec"], yticklabels=["Expert Reject", "Expert Accept"])
    axes[1, 1].set_title("Decision Consistency")

    plt.tight_layout()
    st.pyplot(fig)
