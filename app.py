import os
import sys

try:
    from src.medguider import CONFIG, EngineeringEngine, generate_engineering_data, PatientProfile
except Exception:
    # å…¼å®¹ç›´æ¥åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œæˆ–è¢«å…¶ä»– runner å¯¼å…¥çš„æƒ…å†µï¼šç¡®ä¿å¯å¯¼å…¥ `medguider`
    sys.path.insert(0, os.path.join(os.path.dirname(__file__), "src"))
    from medguider import CONFIG, EngineeringEngine, generate_engineering_data, PatientProfile


def main():
    import streamlit as st
    import pandas as pd
    import numpy as np
    import json
    import matplotlib.pyplot as plt
    import seaborn as sns
    from sklearn.metrics import recall_score, f1_score, precision_recall_curve, confusion_matrix

    # é¡µé¢é…ç½®ï¼ˆå¿…é¡»åœ¨å…¶ä»– st.* ä¹‹å‰è°ƒç”¨ï¼‰
    st.set_page_config(page_title="è€å¹´é™ªè¯Šæ¨èç³»ç»Ÿ v0.3", layout="wide")

    # åˆå§‹åŒ– Session State
    if "config" not in st.session_state:
        st.session_state.config = CONFIG.copy()

    # ä¾§è¾¹æ ï¼šé…ç½®å‚æ•°
    st.sidebar.header("âš™ï¸ ç³»ç»Ÿå‚æ•°é…ç½®")

    with st.sidebar.expander("æƒé‡åˆ†åˆ†é… (Weights)", expanded=True):
        st.session_state.config["weights"]["ability_mu"] = st.slider(
            "èŒä¸šèƒ½åŠ›æƒé‡ (Ability)", 0.0, 1.0, st.session_state.config["weights"]["ability_mu"]
        )
        st.session_state.config["weights"]["attitude_rho"] = st.slider(
            "æœåŠ¡æ€åº¦æƒé‡ (Attitude)", 0.0, 1.0, st.session_state.config["weights"]["attitude_rho"]
        )
        st.session_state.config["weights"]["similarity_lambda"] = st.slider(
            "ç”»åƒå¥‘åˆæƒé‡ (Similarity)", 0.0, 1.0, st.session_state.config["weights"]["similarity_lambda"]
        )
        st.session_state.config["weights"]["active_iota"] = st.slider(
            "æ´»è·ƒ/ç»éªŒæƒé‡ (Active)", 0.0, 1.0, st.session_state.config["weights"]["active_iota"]
        )

    st.sidebar.markdown("---")
    st.sidebar.header("ğŸ§ª å®éªŒè®¾ç½®")
    n_samples = st.sidebar.number_input("æ¨¡æ‹Ÿæ ·æœ¬é‡", 100, 2000, 600)
    threshold = st.sidebar.slider("æ¨èåˆ¤å®šé˜ˆå€¼", 0.0, 1.0, st.session_state.config["params"]["satisfaction_threshold"])
    st.session_state.config["params"]["satisfaction_threshold"] = threshold

    # ä¸»ç•Œé¢
    st.title("ğŸ¥ è€å¹´é™ªè¯Šæ¨èç³»ç»Ÿ - äº¤äº’åŒ–å®éªŒå¹³å°")
    st.markdown(
        """
    æœ¬ç³»ç»Ÿé€šè¿‡**å¤šç»´åº¦ç”»åƒå»ºæ¨¡**ï¼ˆèƒ½åŠ›ã€æ€åº¦ã€éœ€æ±‚å¥‘åˆåº¦ã€æ´»è·ƒåº¦ï¼‰ä¸ºè€å¹´æ‚£è€…æ¨èæœ€åˆé€‚çš„é™ªè¯Šå‘˜ã€‚
    æ‚¨å¯ä»¥é€šè¿‡å·¦ä¾§è¾¹æ è°ƒæ•´ç®—æ³•æƒé‡ï¼Œå®æ—¶è§‚å¯Ÿç³»ç»Ÿåœ¨ä¸“å®¶æ ‡å‡†ä¸‹çš„æ€§èƒ½è¡¨ç°ã€‚
    """
    )

    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "ğŸš€ åŒ¹é…å®éªŒä¸è¯„ä¼°",
        "ğŸ§ ä¸ªæ¡ˆæ·±åº¦åˆ†æ",
        "ğŸ“Š ç»Ÿè®¡çœ‹æ¿",
        "ğŸ“ æ–‡æœ¬ç»Ÿè®¡çœ‹æ¿",
        "âš™ï¸ é…ç½®å‚æ•°"
    ]) 

    # æ•°æ®å‡†å¤‡
    @st.cache_data
    def get_data(n):
        return generate_engineering_data(n)

    patients, escorts = get_data(n_samples)
    engine = EngineeringEngine(st.session_state.config)

    # æ‰§è¡Œè¯„ä¼°
    train_df, test_df, acc, prec = engine.evaluate_system(patients, escorts)
    rec = recall_score(test_df["truth"], test_df["pred"], zero_division=0)
    f1 = f1_score(test_df["truth"], test_df["pred"], zero_division=0)

    with tab1:
        col1, col2, col3, col4 = st.columns(4)
        col1.metric("å‡†ç¡®ç‡ (Acc)", f"{acc:.4f}")
        col2.metric("ç²¾ç¡®ç‡ (Pre)", f"{prec:.4f}")
        col3.metric("å¬å›ç‡ (Rec)", f"{rec:.4f}")
        col4.metric("F1 åˆ†æ•°", f"{f1:.4f}")

        st.subheader("ğŸ” Top 10 æœ€ä½³åŒ¹é…æ¡ˆä¾‹")
        patient_map = {p.pid: p for p in patients}
        escort_map = {e.eid: e for e in escorts}
        
        top_matches = test_df.sort_values(by="score", ascending=False).head(10)
        
        match_display = []
        for _, row in top_matches.iterrows():
            p = patient_map[row["patient_id"]]
            e = escort_map[row["escort_id"]]
            match_display.append({
                "åŒ¹é…åˆ†": row["score"],
                "æ‚£è€…ID": p.pid,
                "æ‚£è€…éœ€æ±‚": ", ".join(p.survey_tags),
                "é™ªè¯Šå‘˜": e.name,
                "èƒ½åŠ›åˆ†": row["ability"],
                "å¥‘åˆåˆ†": row["similarity"],
                "ä¸“å®¶ç»“è®º": "é¦–é€‰" if row["truth"] == 1 else "å¤‡é€‰"
            })
        st.table(pd.DataFrame(match_display))

    with tab2:
        st.subheader("ğŸ” æ¨¡æ‹Ÿå•ä¸ªæ‚£è€…åŒ¹é…")
        p_id = st.selectbox("é€‰æ‹©æµ‹è¯•æ‚£è€… ID", [p.pid for p in patients[:50]])
        target_p = patient_map[p_id]
        
        st.write(f"**æ‚£è€…ç”»åƒ:** {target_p.gender} | {target_p.age}å² | {target_p.education}")
        st.write(f"**æ ¸å¿ƒéœ€æ±‚:** {', '.join(target_p.survey_tags)}")
        
        st.session_state.target_p = target_p # ä¸ºäº†è§¦å‘åˆ·æ–°
        
        # è®¡ç®—å½“å‰æ‚£è€…ä¸æ‰€æœ‰é™ªè¯Šå‘˜çš„åŒ¹é…
        scores = []
        for e in escorts:
            detail = engine.calculate_match_score(target_p, e)
            scores.append({
                "eid": e.eid,
                "name": e.name,
                "score": detail.total_score,
                "ability": detail.ability_component,
                "similarity": detail.similarity_component,
                "attitude": detail.attitude_component,
                "active": detail.active_component
            })
        
        scores_df = pd.DataFrame(scores).sort_values(by="score", ascending=False).head(5)
        
        st.write("---")
        st.write("#### ä¸ºè¯¥æ‚£è€…æ¨èçš„ Top 5 é™ªè¯Šå‘˜ï¼š")
        for _, s in scores_df.iterrows():
            e_obj = escort_map[s["eid"]]
            col_m1, col_m2 = st.columns([1, 2])
            with col_m1:
                st.info(f"**{s['name']}** (å¾—åˆ†: {s['score']:.4f})")
            with col_m2:
                st.write(f"è¯ä¹¦: {', '.join(e_obj.certs) if e_obj.certs else 'æ— '} | è¯„åˆ†: {e_obj.avg_rating}")
                # ç¡®ä¿ä¼ å…¥ st.progress çš„å€¼åœ¨ [0.0, 1.0] èŒƒå›´å†…ï¼Œé¿å… Streamlit æŠ›å‡ºå¼‚å¸¸
                try:
                    prog_val = float(s.get("score", 0.0))
                except Exception:
                    prog_val = 0.0
                prog_val = max(0.0, min(1.0, prog_val))
                st.progress(prog_val, text=f"ç»¼åˆå¥‘åˆåº¦: {s['score']:.2f}")

    with tab3:
        st.subheader("ğŸ“ˆ æ ¸å¿ƒæ€§èƒ½å¯è§†åŒ–")
        
        fig, axes = plt.subplots(2, 2, figsize=(16, 10))
        plt.rcParams["font.sans-serif"] = ["Microsoft YaHei", "SimSun", "Arial Unicode MS"]
        plt.rcParams["axes.unicode_minus"] = False
        
        # 1. P-R Curve
        precisions_curve, recalls_curve, _ = precision_recall_curve(test_df["truth"], test_df["score"])
        axes[0, 0].plot(recalls_curve, precisions_curve, label="P-R Curve", color="darkgreen")
        axes[0, 0].set_xlabel("Recall")
        axes[0, 0].set_ylabel("Precision")
        axes[0, 0].set_title("P-R Curve")
        axes[0, 0].legend()

        # 2. Correlation
        comp_cols = ["ability", "attitude", "similarity", "active", "score"]
        sns.heatmap(test_df[comp_cols].corr(), annot=True, cmap="vlag", ax=axes[0, 1])
        axes[0, 1].set_title("Feature Correlation")

        # 3. Age Groups
        test_df['age_group'] = pd.cut(test_df['p_age'], bins=[60, 70, 80, 95], labels=['60-70', '70-80', '80+'])
        pivot = test_df.pivot_table(values='score', index='age_group', columns='e_cert_count', aggfunc='mean')
        sns.heatmap(pivot, annot=True, fmt=".2f", cmap="YlGnBu", ax=axes[1, 0])
        axes[1, 0].set_title("Score by Age & Certs")

        # 4. Confusion Matrix
        cm = confusion_matrix(test_df["truth"], test_df["pred"])
        cm_norm = cm.astype("float") / cm.sum(axis=1)[:, np.newaxis]
        sns.heatmap(cm_norm, annot=True, fmt=".2%", cmap="Blues", ax=axes[1, 1],
                    xticklabels=["Not Rec", "Rec"], yticklabels=["Expert Reject", "Expert Accept"])
        axes[1, 1].set_title("Decision Consistency")

        plt.tight_layout()
        st.pyplot(fig)

    with tab4:
        st.subheader("ğŸ“ æ–‡æœ¬åŒ–å…³é”®æ•°æ®ä¸ç»Ÿè®¡")
        st.markdown("- **æ ·æœ¬æ€»é‡**:  å…±æœ‰æ‚£è€… & é™ªè¯Šå‘˜ æ ·æœ¬æ•°ï¼Œä»¥åŠæµ‹è¯•é›†åŸºæœ¬ç»Ÿè®¡ã€‚")
        st.write(f"æ‚£è€…æ•°é‡: {len(patients)}ï¼Œé™ªè¯Šå‘˜æ•°é‡: {len(escorts)}")

        st.write("---")
        st.write("**æ•´ä½“åˆ†æ•°ç»Ÿè®¡ï¼ˆæµ‹è¯•é›†ï¼‰**")
        stats = test_df["score"].agg(["count", "mean", "median", "std", "min", "max"]).to_frame().T
        st.table(stats)

        st.write("**åˆ†é¡¹æŒ‡æ ‡æè¿°**")
        comp_stats = test_df[["ability", "attitude", "similarity", "active", "score"]].describe()
        st.dataframe(comp_stats)

        st.write("---")
        st.write("**æ¨èä¸ä¸“å®¶æ ‡æ³¨åˆ†å¸ƒ**")
        dist = pd.DataFrame({
            "é¢„æµ‹": test_df["pred"].value_counts().sort_index(),
            "ä¸“å®¶æ ‡æ³¨": test_df["truth"].value_counts().sort_index(),
        }).fillna(0).astype(int)
        st.table(dist)

        st.write("---")
        st.write("**Top 5 æŒ‰å¹³å‡åˆ†æ’åºçš„é™ªè¯Šå‘˜**")
        escort_scores = test_df.groupby("escort_id")["score"].mean().sort_values(ascending=False).head(5)
        st.table(escort_scores.rename("avg_score").to_frame())

        with st.expander("æŸ¥çœ‹æµ‹è¯•é›†ç¤ºä¾‹è¡Œï¼ˆå‰20è¡Œï¼‰", expanded=False):
            st.dataframe(test_df.head(20))

    with tab5:
        st.subheader("âš™ï¸ å½“å‰é…ç½®å‚æ•°ï¼ˆJSONï¼‰")
        cfg = st.session_state.config
        try:
            cfg_str = json.dumps(cfg, ensure_ascii=False, indent=2)
        except Exception:
            cfg_str = str(cfg)

        st.code(cfg_str, language="json")
        st.download_button("ä¸‹è½½é…ç½® (JSON)", data=cfg_str, file_name="config.json", mime="application/json")


if __name__ == "__main__":
    main()
